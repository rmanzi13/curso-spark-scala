{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbef0956-3931-4f55-b923-68919783b47e",
   "metadata": {},
   "source": [
    "## Spark Scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22727b25-b0e4-4446-865b-d9b66a372c6d",
   "metadata": {},
   "source": [
    "El Spark Scheduler es el responsable de planificar y distribuir las tareas en un clúster de Spark. Su objetivo es optimizar la ejecución de las operaciones definidas en un job (trabajo) de Spark, asegurando que los recursos del clúster se utilicen de manera eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6715cc60-440c-4ca7-b0be-ffe6286413f8",
   "metadata": {},
   "source": [
    "### Funciones principales del Spark Scheduler:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dcae8-ec02-48d9-b7ee-892f13f1625e",
   "metadata": {},
   "source": [
    "#### 1. **División de Jobs en Stages**:\n",
    "\n",
    "- Un job en Spark se divide en stages (etapas) basándose en las dependencias entre las operaciones (transformaciones wide y narrow).\n",
    "\n",
    "- Las operaciones narrow (como map o filter) no requieren un shuffle y se ejecutan en un solo stage.\n",
    "\n",
    "- Las operaciones wide (como groupBy o join) requieren un shuffle y dividen el job en múltiples stages.\n",
    "\n",
    "#### 2. **Planificación de Tareas (Tasks)**:\n",
    "\n",
    "- Cada stage se divide en tasks (tareas), que son las unidades más pequeñas de trabajo.\n",
    "\n",
    "- Cada task se ejecuta en un executor (nodo de trabajo) en el clúster.\n",
    "\n",
    "#### 3. **Asignación de Recursos**:\n",
    "\n",
    "- El scheduler asigna recursos (CPU, memoria) a las tareas, asegurándose de que los executors tengan los recursos necesarios para ejecutar las tareas de manera eficiente.\n",
    "\n",
    "#### 4. **Gestión de Dependencias**:\n",
    "\n",
    "- El scheduler maneja las dependencias entre stages y tareas, asegurándose de que las tareas se ejecuten en el orden correcto.\n",
    "\n",
    "#### 5. **Tolerancia a Fallos**:\n",
    "\n",
    "- Si una tarea falla, el scheduler la vuelve a programar en otro executor para garantizar que el job se complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca08e9-277f-4d35-a895-8b43fd91ebe4",
   "metadata": {},
   "source": [
    "### Componentes del Spark Scheduler\n",
    "**a) DAGScheduler**:\n",
    "\n",
    "- Divide el job en stages basándose en las dependencias entre las operaciones.\n",
    "\n",
    "- Crea un DAG (Directed Acyclic Graph) que representa el flujo de ejecución del job.\n",
    "\n",
    "- Envía los stages al TaskScheduler.\n",
    "\n",
    "**b) TaskScheduler**:\n",
    "\n",
    "- Se encarga de asignar tareas a los executors disponibles en el clúster.\n",
    "\n",
    "- Comunica con el Cluster Manager (como YARN, Mesos o Kubernetes) para obtener recursos.\n",
    "\n",
    "**c) Cluster Manager**:\n",
    "\n",
    "- Gestiona los recursos del clúster (nodos de trabajo, memoria, CPU).\n",
    "\n",
    "- Asigna executors a las aplicaciones de Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb863f37-06a7-4b0c-a833-741268b55cbc",
   "metadata": {},
   "source": [
    "### Proceso de Ejecución en Spark\n",
    "**1. El usuario define un job** (por ejemplo, una consulta SQL o una operación de RDD).\n",
    "\n",
    "**2. El DAGScheduler** divide el job en stages y crea un DAG.\n",
    "\n",
    "**3. El TaskScheduler** asigna tareas a los executors.\n",
    "\n",
    "**4. Los executors** ejecutan las tareas y devuelven los resultados al driver.\n",
    "\n",
    "**5. El proceso se repite** hasta que todas las tareas del job se completan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f86866-18d6-4845-a847-968649598c4c",
   "metadata": {},
   "source": [
    "### : Flujo del Spark Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c54bcd-1ba2-432a-ad55-82650f222433",
   "metadata": {},
   "outputs": [],
   "source": [
    "Job (Usuario)\n",
    "   |\n",
    "   v\n",
    "DAGScheduler (Divide en Stages)\n",
    "   |\n",
    "   v\n",
    "TaskScheduler (Asigna Tasks a Executors)\n",
    "   |\n",
    "   v\n",
    "Executors (Ejecutan Tasks)\n",
    "   |\n",
    "   v\n",
    "Resultados (Devueltos al Driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525eb3c3-0e6a-4624-afff-839cd03212c2",
   "metadata": {},
   "source": [
    "![Plataforma Apache Spark](plataforma-spark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4aaaa-fac6-4ce0-ad4d-7f47ef2cf649",
   "metadata": {},
   "source": [
    "### ¿Cómo funcioan Spark Scheduler?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eff257-d4d8-48e5-8d6b-a943ba635d61",
   "metadata": {},
   "source": [
    "**1. Driver y Executors**:\n",
    "\n",
    "- Cuando ejecutas una aplicación Spark, se inician dos tipos de procesos:\n",
    "\n",
    "  - **Driver**: Es el proceso principal que ejecuta el código de la aplicación (por ejemplo, tu programa en Scala, Python o Java). Aquí es donde vive el Spark Scheduler.\n",
    "\n",
    "  - **Executors**: Son procesos que se ejecutan en los nodos del cluster y se encargan de ejecutar las tareas asignadas por el Driver.\n",
    "\n",
    "**2. Spark Scheduler en el Driver**:\n",
    "\n",
    "- El Spark Scheduler (que incluye el DAGScheduler y el TaskScheduler) es parte del Driver.\n",
    "\n",
    "- Su trabajo es planificar y coordinar la ejecución de tareas en los executors del cluster.\n",
    "\n",
    "- El Driver se comunica con el Cluster Manager (como YARN, Mesos o Kubernetes) para obtener recursos (executors) y luego asigna tareas a esos executors.\n",
    "\n",
    "**3. Cluster Manager**:\n",
    "\n",
    "- El Cluster Manager es el responsable de gestionar los recursos del cluster (nodos, memoria, CPU).\n",
    "\n",
    "- Cuando creas un cluster, estás configurando el Cluster Manager (por ejemplo, YARN o Kubernetes), pero no estás creando un Spark Scheduler directamente.\n",
    "\n",
    "- El Spark Scheduler es parte de la aplicación Spark que se ejecuta en el Driver, no del cluster en sí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc7ca7-6c52-448d-9459-c234f892d33e",
   "metadata": {},
   "source": [
    "### ¿Qué pasa cuando creamos un cluster?\n",
    "Cuando creas un cluster (por ejemplo, con YARN, Kubernetes o Spark Standalone), estás configurando un entorno donde:\n",
    "\n",
    "**1. El Cluster Manager** gestiona los recursos (nodos, memoria, CPU).\n",
    "\n",
    "**2.** Cuando envías una aplicación Spark al cluster:\n",
    "\n",
    "- El Driver de la aplicación se inicia (ya sea en el cluster o en tu máquina local, dependiendo de la configuración).\n",
    "\n",
    "- El Spark Scheduler (dentro del Driver) se comunica con el Cluster Manager para obtener executors.\n",
    "\n",
    "- Los executors ejecutan las tareas asignadas por el Spark Scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f54ee4-3d00-43f8-a0f4-5798b798ed56",
   "metadata": {},
   "source": [
    "### ¿Cuándo se crea una SparkSession?\n",
    "Cuando ejecutas una aplicación Spark, debes crear explícitamente una SparkSession al inicio del programa. \n",
    "\n",
    "**ejemplo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a26c30-5af1-4a56-b347-20d89966a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "// Crear una SparkSession\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"Mi Aplicación Spark\") // Nombre de la aplicación\n",
    "  .master(\"local[*]\")             // Ejecutar en local con todos los núcleos\n",
    "  .getOrCreate()                  // Crear o reutilizar una SparkSession existente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc92fa-0eb4-4597-af75-974b7df329ff",
   "metadata": {},
   "source": [
    "**Explicación del código:**  \n",
    "\n",
    "\n",
    "- **appName(\"MiPrimeraAplicacionSpark\")**: Asigna un nombre a la aplicación, que aparecerá en la interfaz web de Spark.\n",
    "\n",
    "- **master(\"local[*]\")**: Especifica que la aplicación se ejecutará en modo local, utilizando todos los núcleos disponibles.\n",
    "\n",
    "- **.getOrCreate()**: Crea una nueva SparkSession o reutiliza una existente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b874e46-b459-4aad-b53c-7947af5e768c",
   "metadata": {},
   "source": [
    "| Entorno   | Configuración en `.master()`                          |\n",
    "|-----------|------------------------------------------------------|\n",
    "| Local     | `\"local[*]\"` (usa todos los cores disponibles)       |\n",
    "| Standalone | `\"spark://<host>:<puerto>\"` (ejemplo: `\"spark://192.168.1.100:7077\"`) |\n",
    "| YARN      | `\"yarn\"` (modo clúster en Hadoop)                    |\n",
    "| Mesos     | `\"mesos://<host>:<puerto>\"`                          |\n",
    "| Kubernetes | `\"k8s://<kubernetes-master>:<puerto>\"`              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00b728-eb5d-43ea-bc3f-8f0fa2eefed3",
   "metadata": {},
   "source": [
    "- **Local**: Usa todos los núcleos disponibles en la máquina local.\n",
    "\n",
    "- **Standalone**: Conecta a un clúster de Spark en modo independiente.\n",
    "\n",
    "- **YARN**: Ejecuta Spark en un clúster de Hadoop usando YARN como gestor de recursos.\n",
    "\n",
    "- **Mesos**: Ejecuta Spark en un clúster gestionado por Apache Mesos.\n",
    "\n",
    "- **Kubernetes**: Ejecuta Spark en un clúster de Kubernetes.\n",
    "\n",
    "#### Conclusión: Si corres en un clúster, reemplaza \"local[*]\" con la URL de tu clúster o el modo adecuado (yarn, mesos, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97e004-ce16-4ab9-b488-f505934f8b25",
   "metadata": {},
   "source": [
    "### Opciones para .master() según el entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06eef7-7209-4b4c-911b-62e4dab7c612",
   "metadata": {},
   "source": [
    "### ¿Dónde se ejecuta la SparkSession?\n",
    "**La SparkSession** se ejecuta en el **Driver**, que es el proceso principal de tu aplicación Spark. El Driver es responsable de:\n",
    "\n",
    "**1.** Crear y gestionar la SparkSession.\n",
    "\n",
    "**2.** Planificar tareas (a través del Spark Scheduler).\n",
    "\n",
    "**3.** Enviar tareas a los executors en el cluster.\n",
    "\n",
    "**4.** Recopilar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce2857-e896-4113-a703-765332219f09",
   "metadata": {},
   "source": [
    "#### Relación entre SparkSession, SparkContext y Cluster Manager\n",
    "- **SparkSession**:\n",
    "\n",
    "  - Es el punto de entrada de alto nivel para usar Spark.\n",
    "\n",
    "  - Gestiona el SparkContext internamente.\n",
    "\n",
    "- **SparkContext**:\n",
    "\n",
    "  - Es el objeto de bajo nivel que representa la conexión con el cluster.\n",
    "\n",
    "  - Gestiona la comunicación con el Cluster Manager.\n",
    "\n",
    "- **Cluster Manager**:\n",
    "\n",
    "  - Es el responsable de asignar recursos (executors) al SparkContext."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60601c-605b-4179-ac77-58280609f0c1",
   "metadata": {},
   "source": [
    "#### Flujo de ejecución:\n",
    "\n",
    "**1. El SparkContext** se comunica con el clúster para crear un driver y asignar executors a los nodos del clúster.\n",
    "\n",
    "**2. Cuando ejecutas una acción** como rdd.collect() o se envía una aplicación Spark, el SparkContext envía un DAG de la aplicación al Spark Scheduler.\n",
    "\n",
    "**3. El Spark Scheduler divide el trabajo en stages y tasks** según las dependencias (narrow y wide).\n",
    "\n",
    "**4: El Spark Scheduler distribuye las tareas** a los executors disponibles en el clúster.\n",
    "    \n",
    "**5. Los executors** ejecutan las tareas asignadas y devuelven los resultados al driver a través del SparkContext."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5895a-0b93-41e0-bf44-e23e6775af2d",
   "metadata": {},
   "source": [
    "#### Ejemplo de Flujo\n",
    "**1.** Creas una SparkSession en tu aplicación.\n",
    "\n",
    "**2.** La SparkSession crea un SparkContext.\n",
    "\n",
    "**3.** El SparkContext se comunica con el Cluster Manager para obtener recursos.\n",
    "\n",
    "**4.** El Spark Scheduler (dentro del Driver) planifica tareas y las envía a los executors.\n",
    "\n",
    "Los executors ejecutan las tareas y devuelven los resultados al Driver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c18f65-4281-491d-8f59-c8e255a909a9",
   "metadata": {},
   "source": [
    "#### ¿Qué es el Core de Spark?\n",
    "El core de Spark es el módulo base de Apache Spark y proporciona las funcionalidades esenciales para la ejecución distribuida, como:\n",
    "\n",
    "**1.** Gestión de memoria.\n",
    "\n",
    "**2.** Planificación de tareas (Spark Scheduler).\n",
    "\n",
    "**3.** Distribución de datos (RDDs, particiones).\n",
    "\n",
    "**4.** Comunicación entre nodos.\n",
    "\n",
    "**5.** Tolerancia a fallos.\n",
    "\n",
    "El Spark Scheduler es uno de los componentes más importantes del core, ya que se encarga de coordinar la ejecución de tareas en el clúster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d4783-95aa-4ad3-82ea-4fe5cbd37d99",
   "metadata": {},
   "source": [
    "![Arquitectura Apache Spark](arquitectura-spark.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da515421-27f2-40e0-a460-fbb8986eeb3c",
   "metadata": {},
   "source": [
    "#### **El Shell de Spark en Scala**\n",
    "\n",
    "- La forma más sencilla de interactuar con Spark es a través del shell de Scala, que se inicia con el comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac03d2-9d07-4236-97bc-d4427b8ac46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb35da-c827-4a67-997d-856c40372615",
   "metadata": {},
   "source": [
    "- Este shell inicia una SparkSession automáticamente, permitiendo ejecutar código Scala directamente en un entorno interactivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
