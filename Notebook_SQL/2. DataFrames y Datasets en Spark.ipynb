{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8afd9b-c866-4b9f-b3a6-0867993a7800",
   "metadata": {},
   "source": [
    "## 1. DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04050ab-0602-4467-aa39-84683db5ed0e",
   "metadata": {},
   "source": [
    "### ¿Qué es un DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4f511-bcce-41c4-86d1-6f3350e5c4a8",
   "metadata": {},
   "source": [
    "Un DataFrame es una estructura de datos tabular con un esquema definido, similar a una tabla en una base de datos relacional. Está optimizado para el procesamiento distribuido y es una de las abstracciones más utilizadas en Spark para trabajar con datos estructurados.\n",
    "\n",
    "**Características principales:**  \n",
    "\n",
    "- **Estructura tabular:** Organiza los datos en filas y columnas.\n",
    "  \n",
    "\n",
    "- **Esquema:** Define el tipo de datos de cada columna (por ejemplo, entero, cadena, fecha).\n",
    "  \n",
    "\n",
    "- **Optimización:** Utiliza el optimizador Catalyst y el motor de ejecución Tungsten para mejorar el rendimiento.\n",
    "  \n",
    "\n",
    "- **Interoperabilidad:** Puede crearse a partir de múltiples fuentes de datos (CSV, JSON, Parquet, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bcdd8-a5bd-4361-b460-eb539085e6a3",
   "metadata": {},
   "source": [
    "**Similitudes con tablas SQL:**  \n",
    "\n",
    "- Los DataFrames son conceptualmente equivalentes a las tablas en SQL.\n",
    "\n",
    "- Permiten ejecutar consultas SQL directamente sobre ellos.\n",
    "\n",
    "- Ejemplo: SELECT * FROM df WHERE columna > 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3ea55-50a1-4b9d-b748-5c912b8a110a",
   "metadata": {},
   "source": [
    "#### **Creación de DataFrames:**\n",
    "\n",
    "Los DataFrames pueden crearse a partir de diversas fuentes de datos:\n",
    "\n",
    "**1. Desde un archivo CSV:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0288e-563f-4d79-a3b8-4b299f277087",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(\"ruta/al/archivo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b69c34-7c23-4b0c-aae6-a3819724b442",
   "metadata": {},
   "source": [
    "**2. Desde un archivo JSON:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3a218-1465-4aa3-bc95-5f282ba45140",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.read.json(\"ruta/al/archivo.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16f6dc-d63d-4727-ba9e-ed80aaa9ee98",
   "metadata": {},
   "source": [
    "**3. Desde un archivo Parquet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658642f1-fcd3-49c3-b9d3-4e7dcfb2705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = spark.read.parquet(\"ruta/al/archivo.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d007757-7597-48f5-9f04-6262c873a049",
   "metadata": {},
   "source": [
    "**4. Desde una colección de Scala:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bbea8-1318-4f39-8d7f-d50603f77727",
   "metadata": {},
   "outputs": [],
   "source": [
    "val datos = Seq((\"Alice\", 34), (\"Bob\", 45), (\"Cathy\", 29))\n",
    "val df = spark.createDataFrame(datos).toDF(\"Nombre\", \"Edad\")0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c23ae8-229b-4689-87b2-b935274cb2df",
   "metadata": {},
   "source": [
    "#### **Operaciones comunes con DataFrames:**\n",
    "\n",
    "- **Filtrado:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c3338-6526-4280-a977-4745b21a28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dfFiltrado = df.filter(\"Edad > 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2db6b2-b67c-4cc4-8499-401fdad0b2ce",
   "metadata": {},
   "source": [
    "- **Selección de columnas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d338a7-bd81-4a20-aa92-ab690244c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val nombres = df.select(\"Nombre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933431c-d9c0-4c2b-9127-13e940b7e77a",
   "metadata": {},
   "source": [
    "- **Agregaciones:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2e0e3-00f0-4591-b554-99a5e1b75b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val promedioEdad = df.agg(avg(\"Edad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bc91b-de5c-40b9-b84d-d0441b8a5b65",
   "metadata": {},
   "source": [
    "## 2. Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9185b92-7e68-459b-b74e-86ce05d2ccb2",
   "metadata": {},
   "source": [
    "### ¿Qué es un Dataset?\n",
    "\n",
    "Un Dataset es una extensión de los DataFrames que proporciona tipado estático en tiempo de compilación. Combina las ventajas de los DataFrames (optimización y esquema) con la seguridad de tipos de los RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475f01d-d402-4294-9a90-e5ec6aa6a101",
   "metadata": {},
   "source": [
    "#### Ventajas de los Datasets:\n",
    "\n",
    "- **Tipado estático**: Permite detectar errores en tiempo de compilación.  \n",
    "\n",
    "- **Interoperabilidad**: Puede trabajar con objetos de Scala/Java de manera segura.  \n",
    "\n",
    "- **Optimización**: Al igual que los DataFrames, utiliza el optimizador Catalyst.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cb7f1-4b58-413e-8a24-50e94e6d7e9d",
   "metadata": {},
   "source": [
    "#### Creación de Dataset\r\n",
    "\r\n",
    "Los Datasets se crean a partir de DataFrames o colecciones de objetos.  \r\n",
    "\r\n",
    "**1. Desde un DataFrame:**\r\n",
    "e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff4423-0d28-46a9-8dfc-2a0549ff8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Persona(Nombre: String, Edad: Int)\n",
    "val ds = df.as[Persona]  // Convertir DataFrame a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5b769-c85b-456c-aa8f-4b9e57a04795",
   "metadata": {},
   "source": [
    "**2. Desde una colección de Scala:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c9010-b2b7-4b54-a1bd-4d40034b1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "val datos = Seq(Persona(\"Alice\", 34), Persona(\"Bob\", 45))\n",
    "val ds = spark.createDataset(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4c51b-d836-45d8-8e2e-54d047ed6f93",
   "metadata": {},
   "source": [
    "#### Operaciones comunes con Datasets:\n",
    "- **Filtrado**o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ad043-76f7-42a1-93c9-75a212204bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dsFiltrado = ds.filter(_.Edad > 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f753d88-6698-4880-a575-06d891158db9",
   "metadata": {},
   "source": [
    "- **Transformaciones**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4c982-5102-4c0f-a4a8-fcbf813533b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val nombres = ds.map(_.Nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c8700-a485-4f75-bc85-a71f7d5c0bdf",
   "metadata": {},
   "source": [
    "## 3. Conversión entre DataFrames y Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d244e-10a3-4225-840a-5d7fca1dc46e",
   "metadata": {},
   "source": [
    "**De DataFrame a Dataset**:  \n",
    "Para convertir un DataFrame a un Dataset, se necesita definir un tipo de dato (case class en Scala)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f3ff3-c174-4d86-b0fa-1b86d3e14165",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Persona(Nombre: String, Edad: Int)\n",
    "val ds = df.as[Persona]  // DataFrame -> Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d74f2-a871-47c9-8ee9-c51a99b16274",
   "metadata": {},
   "source": [
    "**De Dataset a DataFrame**:  \n",
    "Un Dataset puede convertirse fácilmente en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea0cfa-765e-433f-a9dc-12396427ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "val df = ds.toDF()  // Dataset -> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7725b-3e73-4e97-9161-50f50eab8c41",
   "metadata": {},
   "source": [
    "**Ejemplo Práctico:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d6a92-d784-47b1-8b40-6ab0a637c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear un DataFrame desde un archivo CSV\n",
    "val df = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(\"ruta/al/archivo.csv\")\n",
    "\n",
    "// Convertir DataFrame a Dataset\n",
    "case class Persona(Nombre: String, Edad: Int)\n",
    "val ds = df.as[Persona]\n",
    "\n",
    "// Filtrar el Dataset\n",
    "val dsFiltrado = ds.filter(_.Edad > 30)\n",
    "\n",
    "// Convertir Dataset a DataFrame\n",
    "val dfFiltrado = dsFiltrado.toDF()\n",
    "\n",
    "// Mostrar resultados\n",
    "dfFiltrado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bba13-9051-4a17-8ccd-1250e533ac7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
