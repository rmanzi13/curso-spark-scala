{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b50d98-6ad0-41ab-9bc3-bac4ba80b896",
   "metadata": {},
   "source": [
    "### 1. Ejercicio con Broadcast\n",
    "\n",
    "#### **Descripci칩n**:\n",
    "\n",
    "- Tienes una lista de categor칤as de productos en un Map. Luego, tienes un DataFrame con ventas que solo tiene el id_categoria.\n",
    "  \n",
    "- Tu tarea es agregar la categor칤a usando broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b402f6a-7bd3-4ea2-b203-cd02b92dd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.broadcast.Broadcast\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"EjercicioBroadcast\").master(\"local\").getOrCreate()\n",
    "import spark.implicits._\n",
    "\n",
    "// Mapa con categor칤as de productos\n",
    "val categorias = Map(1 -> \"Electr칩nica\", 2 -> \"Hogar\", 3 -> \"Deportes\")\n",
    "\n",
    "// Crear variable compartida\n",
    "val categoriasBroadcast: Broadcast[Map[Int, String]] = spark.sparkContext.broadcast(categorias)\n",
    "\n",
    "// 游 Simular ventas (id_venta, id_categoria, cantidad)\n",
    "val ventasDF = Seq((101, 1, 5), (102, 3, 2), (103, 2, 8)).toDF(\"id_venta\", \"id_categoria\", \"cantidad\")\n",
    "\n",
    "// AREA: Agregar la columna \"nombre_categoria\" usando el broadcast\n",
    "val resultadoDF = ventasDF.withColumn(\"nombre_categoria\", ???)\n",
    "\n",
    "// Mostrar resultados\n",
    "resultadoDF.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8336b-ad5d-410d-b57c-bc7e3492af67",
   "metadata": {},
   "source": [
    "### Preguntas:\n",
    "\n",
    "**1.** 쮺칩mo accediste al Map dentro del broadcast para agregar el nombre de la categor칤a?\n",
    "\n",
    "**2.** 쯈u칠 pasa si el id_categoria no est치 en el Map? 쮺칩mo lo manejas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b2e32-ec72-4b87-bbdc-fb539152df31",
   "metadata": {},
   "source": [
    "### 2. Ejercicio con Accumulators\n",
    "\n",
    "#### **Descripci칩n**:\n",
    "\n",
    "- Tienes un DataFrame de ventas con montos. T\n",
    "- Tu tarea es contar cu치ntas ventas superan los $100 usando un Accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4c2d2-f160-448f-aad3-07e9b6c97f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear acumulador para contar ventas grandes\n",
    "val ventasGrandes = spark.sparkContext.longAccumulator(\"Ventas > 100\")\n",
    "\n",
    "// Simular ventas (id_venta, monto)\n",
    "val ventasDF = Seq((101, 150), (102, 80), (103, 200)).toDF(\"id_venta\", \"monto\")\n",
    "\n",
    "// TAREA: Usar foreach para contar cu치ntas ventas son mayores a 100\n",
    "ventasDF.??? \n",
    "\n",
    "// Mostrar resultado\n",
    "println(s\"Total de ventas mayores a 100: ${ventasGrandes.value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb42839-1f99-42be-a61a-5774f1d2ccc4",
   "metadata": {},
   "source": [
    "### Preguntas:\n",
    "\n",
    "**1.** 쮺칩mo usaste el acumulador para contar ventas mayores a 100?\n",
    "\n",
    "**2.** 쯇or qu칠 no se puede usar map() en lugar de foreach()?\n",
    "\n",
    "**3.** 쮺칩mo cambiar칤as el c칩digo para contar ventas mayores a 50 en lugar de 100?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c88c16-cb2a-4605-a2ad-90ccceec9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (row.getAs[Int](\"monto\") > 50) {\n",
    "  ventasGrandes.add(1)\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
