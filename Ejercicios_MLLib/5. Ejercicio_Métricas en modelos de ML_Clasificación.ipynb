{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9956d2ac-dc1d-49f9-955c-09cea505f2b8",
   "metadata": {},
   "source": [
    "### a) Métricas de Clasificación\n",
    "\n",
    "**1.** **Precisión (Precision)**:\n",
    "\n",
    "- Mide la proporción de predicciones positivas que son correctas.\n",
    "\n",
    "- Fórmula: Precision = TP / (TP + FP)\n",
    "\n",
    "   - **TP**: Verdaderos positivos.\n",
    "\n",
    "   - **FP**: Falsos positivos.\n",
    "\n",
    "**2.** **Recall (Sensibilidad)**:\n",
    "\n",
    "- Mide la proporción de positivos reales que son correctamente identificados.\n",
    "\n",
    "- Fórmula: Recall = TP / (TP + FN)\n",
    "\n",
    "   - FN: Falsos negativos.\n",
    "\n",
    "**3.** **F1-Score**:\n",
    "\n",
    "- Es la media armónica de la precisión y el recall.\n",
    "\n",
    "- Fórmula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "**4.** **AUC (Área bajo la curva ROC)**:\n",
    "\n",
    "- Mide la capacidad del modelo para distinguir entre clases.\n",
    "\n",
    "- Un valor de 1 indica un modelo perfecto, mientras que 0.5 indica un modelo aleatorio.\n",
    "\n",
    "### b ) Métricas de Regresión\n",
    "\n",
    "**1.** **RMSE (Root Mean Squared Error)**:\n",
    "\n",
    "- Mide la diferencia entre los valores predichos y los reales.\n",
    "\n",
    "- Fórmula: RMSE = sqrt(mean((y_pred - y_true)^2))\n",
    "\n",
    "**2.** **R² (Coeficiente de Determinación)**:\n",
    "\n",
    "- Mide cuánta variabilidad de la variable dependiente es explicada por el modelo.\n",
    "\n",
    "- Un valor de 1 indica un ajuste perfecto, mientras que 0 indica que el modelo no explica nada.\n",
    "\n",
    "**3.** **MAE (Mean Absolute Error)**:\n",
    "\n",
    "- Mide el error absoluto promedio entre los valores predichos y los reales.\n",
    "\n",
    "- Fórmula: MAE = mean(|y_pred - y_true|)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ff08d-2506-42eb-a990-455b76017aad",
   "metadata": {},
   "source": [
    "#### Implementación Práctica\n",
    "\n",
    "- **Dataset**: Wine Quality (winequality-red.csv)\n",
    "- **Clasificación**: Predecir si un vino es de alta calidad (quality >= 7) o no (quality < 7).\n",
    "\n",
    "- **Regresión**: Predecir la calidad del vino (quality) como un valor numérico.\n",
    "\n",
    "**Clasificación**: Métricas de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fdeca9-bbf3-4816-b866-239d48bbe3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@1730877d\n",
       "data = [fixed_acidity: double, volatile_acidity: double ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[fixed_acidity: double, volatile_acidity: double ... 10 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "// 1. Crear una sesión de Spark\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"Classification Metrics Example\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()\n",
    "\n",
    "// 2. Cargar el dataset winequality-red\n",
    "val data = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"winequality-red.csv\") // Reemplaza con la ruta correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a0a294-81ac-4daf-8203-e10b7fcd5fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labeledData = [fixed_acidity: double, volatile_acidity: double ... 11 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[fixed_acidity: double, volatile_acidity: double ... 11 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "// 3. Crear una columna binaria para clasificación (alta calidad: 1, baja calidad: 0)\n",
    "val labeledData = data.withColumn(\"high_quality\", when($\"quality\" >= 7, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d4b2b4-6781-4328-bc6e-c4397f24efb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException = null\n",
       "featureColumns = Array(fixed_acidity, volatile_acidity, citric_acid, residual_sugar, chlorides, free_sulf_dioxide, total_sulfur_dioxide, density, pH, sulphates, alcohol)\n",
       "assembler = VectorAssembler: uid=vecAssembler_372491626417, handleInvalid=error, numInputCols=11\n",
       "assembledData = [fixed_acidity: double, volatile_acidity: double ... 12 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[fixed_acidity: double, volatile_acidity: double ... 12 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 4. Preparar los datos: Crear un vector de características\n",
    "val featureColumns = Array(\n",
    "  \"fixed_acidity\", \"volatile_acidity\", \"citric_acid\", \"residual_sugar\",\n",
    "  \"chlorides\", \"free_sulf_dioxide\", \"total_sulfur_dioxide\", \"density\",\n",
    "  \"pH\", \"sulphates\", \"alcohol\"\n",
    ")\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureColumns)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val assembledData = assembler.transform(labeledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd2056-0491-48cd-9868-3406622c92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 5. Dividir los datos en conjuntos de entrenamiento y prueba (80% - 20%)\n",
    "val Array(trainingData, testData) = assembledData.randomSplit(Array(0.8, 0.2), seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6e5be-4fe4-4037-bbf1-31dcd40a238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "\n",
    "// 6. Entrenar un modelo de clasificación (Random Forest)\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"high_quality\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setNumTrees(50)\n",
    "  .setSeed(42)\n",
    "\n",
    "val model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3ce0b-38eb-44f1-8684-e717cf567645",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 7. Hacer predicciones sobre el conjunto de prueba\n",
    "val predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1a57d-f385-408c-8aab-e13aa658f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 8. Calcular métricas de clasificación\n",
    "val evaluator = new MulticlassClassificationEvaluator()\n",
    "  .setLabelCol(\"high_quality\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "\n",
    "val accuracy = evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "val precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "val recall = evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "val f1 = evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "\n",
    "println(s\"Exactitud (Accuracy): $accuracy\")\n",
    "println(s\"Precisión (Precision): $precision\")\n",
    "println(s\"Recall: $recall\")\n",
    "println(s\"F1-Score: $f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30269464-735f-4857-a4df-5664a7b61168",
   "metadata": {},
   "outputs": [],
   "source": [
    "// 9. Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7d256-e86e-4a23-ac72-0f90ff206aeb",
   "metadata": {},
   "source": [
    "### Interpretación de Resultados\n",
    "\n",
    "- **Clasificación**:\n",
    "\n",
    "   - **Exactitud (Accuracy)**: El porcentaje de predicciones correctas.\n",
    "\n",
    "   - **Precisión (Precision)**: La proporción de vinos predichos como de alta calidad que realmente lo son.\n",
    "\n",
    "    - **Recall**: La proporción de vinos de alta calidad que fueron correctamente identificados.\n",
    "\n",
    "    - **F1-Score**: Un balance entre precisión y recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603af9a-ac24-456f-a0da-82cdbf2f196b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
