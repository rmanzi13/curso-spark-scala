{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0396c10-d001-4865-a4e6-037ca867996d",
   "metadata": {},
   "source": [
    "## Mantenimiento y Extensión de Proyectos Spark con Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1fb241-dcf7-4dc5-9bad-125755ad44f4",
   "metadata": {},
   "source": [
    "### 1. Consejos y Buenas Prácticas para Mantener y Extender Proyectos de Spark con Scala\n",
    "Mantener y extender proyectos Spark requiere enfoques estructurados y buenas prácticas:\n",
    "\n",
    "- **Código modular**: Dividir el código en funciones y clases reutilizables.\n",
    "\n",
    "- **Documentación**: Comentar el código y mantener un README actualizado.\n",
    "\n",
    "- **Pruebas automatizadas**: Implementar pruebas unitarias y de integración.\n",
    "\n",
    "- **Control de versiones**: Usar Git para gestionar cambios y colaboración.\n",
    "\n",
    "- **Refactorización**: Mejorar el código existente sin alterar su funcionalidad.\n",
    "\n",
    "- **Manejo de dependencias**: Mantener actualizadas las librerías y evitar conflictos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd60147-bb65-475f-9550-3c365df5fe05",
   "metadata": {},
   "source": [
    "### 2. Introducción a Spark con YARN\n",
    "YARN (Yet Another Resource Negotiator) es un gestor de recursos de Hadoop que permite ejecutar aplicaciones Spark en clústeres Hadoop:\n",
    "\n",
    "- **Ventajas**:\n",
    "\n",
    "  - Integración nativa con el ecosistema Hadoop.\n",
    "\n",
    "  - Gestión eficiente de recursos en clústeres grandes.\n",
    "\n",
    "- **Configuración**:\n",
    "\n",
    "  - Especificar --master yarn en spark-submit.\n",
    "\n",
    "  - Definir modos de despliegue: cluster o client.\n",
    "\n",
    "**Ejemplo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edab0d7-3b47-4378-8cf5-21408e194548",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit \\\n",
    "  --class com.ejemplo.MiApp \\\n",
    "  --master yarn \\\n",
    "  --deploy-mode cluster \\\n",
    "  mi-proyecto-spark.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11297b-c420-4a0b-ba8a-63abb5c8883e",
   "metadata": {},
   "source": [
    "### 3. Introducción a Spark con Mesos\n",
    "Apache Mesos es un gestor de recursos distribuido que puede ejecutar aplicaciones Spark:\n",
    "\n",
    "- **Ventajas**:\n",
    "\n",
    "  - Escalabilidad y tolerancia a fallos.\n",
    "\n",
    "  - Soporte para múltiples frameworks (Spark, Kafka, etc.).\n",
    "\n",
    "- **Configuración**:\n",
    "\n",
    "  - Especificar --master mesos://<mesos-master-url> en spark-submit.\n",
    "\n",
    "**Ejemplo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717aab7-5ace-4783-89ea-0ad7a3cb89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit \\\n",
    "  --class com.ejemplo.MiApp \\\n",
    "  --master mesos://<mesos-master-url> \\\n",
    "  mi-proyecto-spark.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccec50-b890-4e94-8a8e-9c91a37086cd",
   "metadata": {},
   "source": [
    "### 4. Comparativa entre Spark con YARN vs Mesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3105a-270a-4c5b-90b9-aa56db80e01f",
   "metadata": {},
   "source": [
    "| Característica            | YARN                          | Mesos                        |\r\n",
    "|---------------------------|------------------------------|------------------------------|\r\n",
    "| Integración Hadoop        | Nativa                       | Requiere configuración adicional |\r\n",
    "| Escalabilidad            | Alta                         | Muy alta                     |\r\n",
    "| Facilidad de uso         | Fácil en entornos Hadoop     | Más complejo                 |\r\n",
    "| Soporte multi-framework  | Limitado                     | Amplio                       |\r\n",
    "| Comunidad                | Grande (Hadoop)              | Menor que YARN               |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bc231-6320-4fe2-91ec-e9cd8f0ec0f6",
   "metadata": {},
   "source": [
    "### 5. Consejos para Configuraciones de Redes de Clústeres Escalables\n",
    "Redes de alta velocidad: Usar redes de 10GbE o superiores para minimizar cuellos de botella.\n",
    "\n",
    "- **Configuración de buffers**: Ajustar parámetros como spark.network.timeout y spark.shuffle.io.numConnectionsPerPeer.\n",
    "\n",
    "- **Balanceo de carga**: Distribuir uniformemente el tráfico entre nodos.\n",
    "\n",
    "- **Monitoreo de red**: Usar herramientas como Ganglia o Prometheus para detectar problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15609521-ef9c-4350-8aca-a4068b9d0ed1",
   "metadata": {},
   "source": [
    "### 6. Breve Introducción a las Estrategias de Replicación\n",
    "La replicación es clave para garantizar la disponibilidad y tolerancia a fallos:\n",
    "\n",
    "- Replicación de datos: Almacenar copias de datos en múltiples nodos.\n",
    "\n",
    "- Replicación de tareas: Ejecutar tareas críticas en varios nodos.\n",
    "\n",
    "- Configuraciones en Spark:\n",
    "  - spark.storage.replication: Controla el número de réplicas en RDDs.\n",
    "\n",
    "  - spark.shuffle.replication: Replica datos durante operaciones de shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e694f75-f369-4eff-a59c-c39a1cac8ea6",
   "metadata": {},
   "source": [
    "### 7. Breve Introducción a la Monitorización\n",
    "La monitorización es esencial para garantizar el rendimiento y la estabilidad:\n",
    "\n",
    "- **Interfaz web de Spark**: Proporciona métricas en tiempo real sobre jobs, tareas y uso de recursos.\n",
    "\n",
    "- **Herramientas externas**:\n",
    "\n",
    "   - **Ganglia**: Para métricas de clúster.\n",
    "\n",
    "   - **Prometheus + Grafana**: Para visualización avanzada.\n",
    "\n",
    "   - **ELK Stack**: Para análisis de logs.\n",
    "\n",
    "- **Métricas clave**:\n",
    "\n",
    "   - Tiempo de ejecución de tareas.\n",
    "\n",
    "   - Uso de CPU y memoria.\n",
    "\n",
    "   - Operaciones de shuffle y E/S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589a995-79d8-4d66-bdc4-98bcc7b126df",
   "metadata": {},
   "source": [
    "### 8. Detección de Problemas Comunes: Planes de Ejecución y Shuffle\n",
    "-  **Planes de ejecució**:\n",
    "\n",
    "   - Usar df.explain() para analizar el plan de ejecución.\n",
    "\n",
    "   - Evitar operaciones costosas como crossJoin o groupBy sin filtros.\n",
    "\n",
    "- **Problemas de shuffle**:\n",
    "\n",
    "   - inimizar el shuffle usando coalesce o repartition.\n",
    "\n",
    "   - Ajustar spark.sql.shuffle.partitions para optimizar el número de particiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7e4e3-ce79-4b5e-af31-7db539a36fd1",
   "metadata": {},
   "source": [
    "### 9. Consideraciones para Desarrollo Seguro\n",
    "- **Autenticación y autorización**:\n",
    "\n",
    "   - Usar Kerberos para autenticación en clústeres Hadoop.\n",
    "\n",
    "   - Configurar ACLs para controlar el acceso a recursos.\n",
    "\n",
    "- **Cifrado**:\n",
    "\n",
    "   - Habilitar cifrado en tránsito (TLS/SSL) y en reposo.\n",
    "\n",
    "- **Gestión de secretos**:\n",
    "\n",
    "   - Usar herramientas como Vault o AWS Secrets Manager para gestionar credenciales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce137758-fbaa-4402-b115-62b749c0166d",
   "metadata": {},
   "source": [
    "### 10. Recomendaciones para Establecer Aplicaciones Mantenibles de Spark\n",
    "- **Código limpio**: Seguir principios SOLID y patrones de diseño.\n",
    "\n",
    "- **Configuraciones externas**: Usar archivos de configuración (ej. application.conf) en lugar de hardcodear valores.\n",
    "\n",
    "- **Logging**: Implementar logs estructurados con niveles adecuados (INFO, DEBUG, ERROR).\n",
    "\n",
    "- **Documentación**: Mantener documentación actualizada sobre la arquitectura y flujos de trabajo.\n",
    "\n",
    "- **Integración continua**: Automatizar pruebas y despliegues con CI/CD (Jenkins, GitLab CI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b0264-0823-4b31-8324-f9b8b2a99c45",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "Mantener y extender proyectos Spark con Scala requiere un enfoque estructurado, desde la elección del gestor de recursos (YARN, Mesos) hasta la implementación de buenas prácticas de desarrollo y monitorización. Siguiendo estas recomendaciones, se pueden construir aplicaciones escalables, seguras y fáciles de mantener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758695b-57ec-4171-8a26-3a2d67d60cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
