{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945aa9c6-9475-414d-87c8-745970b2ef2c",
   "metadata": {},
   "source": [
    "## Fundamentos de MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55199956-e3d2-4e87-ad69-1ef60f96273a",
   "metadata": {},
   "source": [
    "### 1. Estimadores: Concepto y rol en el entrenamiento de modelos\n",
    "En Spark MLlib, los Estimadores son algoritmos o componentes que aprenden de los datos para generar un modelo. Su principal función es ajustar un conjunto de datos de entrada y producir un modelo que pueda ser utilizado para hacer predicciones o inferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee939b2-f7d5-45b2-a1d2-eb1ddf514a8c",
   "metadata": {},
   "source": [
    "- Concepto clave:\n",
    "\n",
    "  - Los estimadores implementan el método .fit(), que toma un DataFrame como entrada y devuelve un Modelo (Transformer).\n",
    "\n",
    "  - El modelo resultante es un Transformer porque puede transformar nuevos datos en predicciones.\n",
    "\n",
    "- Ejemplos de estimadores:\n",
    "\n",
    "  - LinearRegression: Ajusta un modelo de regresión lineal.\n",
    "\n",
    "  - LogisticRegression: Entrena un modelo de clasificación binaria o multiclase.\n",
    "\n",
    "  - KMeans: Genera un modelo de clustering utilizando el algoritmo K-Means.\n",
    "\n",
    "- Rol en el entrenamiento de modelos:\n",
    "\n",
    "  - Los estimadores son responsables de encontrar los parámetros óptimos del modelo que minimizan una función de pérdida (en el caso de aprendizaje supervisado) o maximizan una métrica de agrupación (en el caso de aprendizaje no supervisado).\n",
    "\n",
    "  - Permiten la automatización del proceso de entrenamiento, especialmente cuando se integran en un Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbbaf6-7c7c-4351-a9ea-6e624d95955c",
   "metadata": {},
   "source": [
    "### 2. Entrenamiento y evaluación de modelos\n",
    "El proceso de entrenamiento y evaluación de modelos en Spark MLlib sigue un flujo de trabajo estructurado:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a246f01-9d71-4c01-9c5d-35b56fcc2a96",
   "metadata": {},
   "source": [
    "#### **1.** Preparación de datos:\n",
    "\n",
    "- Limpieza y transformación de datos (por ejemplo, normalización, codificación de variables categóricas).\n",
    "\n",
    "- División del conjunto de datos en train (entrenamiento) y test (prueba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa3cd4-506b-4ea4-8910-5cc82d1101bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val Array(trainingData, testData) = data.randomSplit(Array(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405cbea-d48e-4570-9d8b-35eb00989d0c",
   "metadata": {},
   "source": [
    "#### **2.** Entrenamiento del modelo:\n",
    "\n",
    "- Se utiliza el método .fit() del estimador para entrenar el modelo con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faeae42-9e78-4058-8a63-3fb071686579",
   "metadata": {},
   "outputs": [],
   "source": [
    "val lr = new LinearRegression()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "val model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd700d2e-43d5-4cf8-ab4f-06f59687789a",
   "metadata": {},
   "source": [
    "#### **3.** Evaluación del modelo:\n",
    "\n",
    "- Se utilizan métricas específicas para evaluar el rendimiento del modelo en los datos de prueba.\n",
    "\n",
    "- Spark MLlib proporciona herramientas para calcular métricas comunes, como:\n",
    "\n",
    "  - Regresión:\n",
    "\n",
    "    - Error cuadrático medio (MSE).\n",
    "\n",
    "    - Coeficiente de determinación (R²).\n",
    "\n",
    "  - Clasificación:\n",
    "\n",
    "    - Precisión (Accuracy).\n",
    "\n",
    "    - Matriz de confusión.\n",
    "\n",
    "    - Área bajo la curva ROC (AUC).\n",
    "\n",
    "  - Clustering:\n",
    "\n",
    "     - Silhouette Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112e488-0d4f-4b87-8c07-60938a6df16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "\n",
    "val predictions = model.transform(testData)\n",
    "val evaluator = new RegressionEvaluator()\n",
    "  .setLabelCol(\"label\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(s\"Root Mean Squared Error (RMSE): $rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33e23f-56ce-4918-b800-bb1142e52aca",
   "metadata": {},
   "source": [
    "## 3. Persistencia y aplicación de modelos\n",
    "Una vez entrenado y evaluado un modelo, es importante poder guardarlo para su uso futuro o en aplicaciones en producción. Spark MLlib proporciona métodos para guardar y cargar modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5dfa3-f561-4893-8b75-e37264c63af4",
   "metadata": {},
   "source": [
    "#### **1.** Persistencia de modelos:\n",
    "\n",
    "- Los modelos entrenados pueden guardarse en disco para su uso posterior.\n",
    "\n",
    "- Esto es especialmente útil en entornos de producción donde el modelo debe ser reutilizado sin necesidad de reentrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b7770-2940-4739-a149-167fc53209f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"path/to/save/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1aee66-7218-40b1-bb43-06c24da44ae5",
   "metadata": {},
   "source": [
    "#### **2.** Carga de modelos:\n",
    "\n",
    "- Los modelos guardados pueden cargarse en cualquier momento para hacer predicciones sobre nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ed2aa-f8b6-4fbf-97a1-a1135a58dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegressionModel\n",
    "\n",
    "val loadedModel = LinearRegressionModel.load(\"path/to/save/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431f792-4ec7-4992-a8ee-cf511e76ae32",
   "metadata": {},
   "source": [
    "#### **3.** Aplicación de modelos:\n",
    "\n",
    "- Una vez cargado, el modelo puede utilizarse para transformar nuevos datos y generar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff78b1-78e1-4817-92bd-a021556b0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "val newPredictions = loadedModel.transform(newData)\n",
    "newPredictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d3d29-06aa-4507-a7e3-5dfa6bd93bd1",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros y selección de modelos:\n",
    "\n",
    "- Técnicas como Cross-Validation y Grid Search para encontrar los mejores hiperparámetros.\n",
    "\n",
    "- Uso de herramientas como CrossValidator y ParamGridBuilder en Spark MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954af7d8-7cf1-4057-8a35-15646ce615b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
