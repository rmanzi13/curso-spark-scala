{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae8aaf4-e12d-4efb-bafc-ed56bd93d29b",
   "metadata": {},
   "source": [
    "## Optimización de Hiperparámetros y Selección de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69b5bf-f0e3-4e55-9e7e-9695df65ade3",
   "metadata": {},
   "source": [
    "Los **hiperparámetros** son configuraciones que se definen antes de entrenar un modelo de Machine Learning. A diferencia de los parámetros del modelo (que se aprenden durante el entrenamiento), los hiperparámetros no se aprenden y deben ser ajustados manualmente.\n",
    "\n",
    "- Profundidad máxima de un árbol de decisión.\n",
    "\n",
    "- Número de árboles en un Random Forest.\n",
    "\n",
    "- Tasa de aprendizaje en un modelo de Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65663ac-1c5c-4500-bb0e-cae7ce3473c3",
   "metadata": {},
   "source": [
    "### Por qué es importante optimizar los hiperparámetros?\n",
    "La elección de los hiperparámetros puede tener un impacto significativo en el rendimiento del modelo. Unos hiperparámetros mal elegidos pueden llevar a:\n",
    "\n",
    "- **Sobreajuste (overfitting)**: El modelo se ajusta demasiado a los datos de entrenamiento y no generaliza bien a nuevos datos.\n",
    "\n",
    "- **Subajuste (underfitting)**: El modelo es demasiado simple y no captura los patrones subyacentes en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fc5fd-46b7-421c-80e7-1629a72ad665",
   "metadata": {},
   "source": [
    "### Técnicas para la Optimización de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75953cc7-4a71-4690-a57f-14d92d47c20c",
   "metadata": {},
   "source": [
    "#### **1.** **Grid Search** (Búsqueda en Rejilla)\n",
    "\n",
    "- **Grid Search** es una técnica que prueba todas las combinaciones posibles de hiperparámetros en una \"rejilla\" predefinida.\n",
    "\n",
    "- Por ejemplo, si tienes dos hiperparámetros con 3 valores posibles cada uno, Grid Search probará 9 combinaciones.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Es exhaustivo: prueba todas las combinaciones posibles.\n",
    "\n",
    "- Fácil de implementar.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Computacionalmente costoso, especialmente con muchos hiperparámetros o valores posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da9add-53be-4bdd-b96a-92d63f4efef2",
   "metadata": {},
   "source": [
    "#### **2.** **Cross-Validation** (Validación Cruzada)\n",
    "\n",
    "- **Cross-Validation** es una técnica para evaluar el rendimiento del modelo de manera robusta.\n",
    "\n",
    "- Divide los datos en k particiones (folds), entrena el modelo en k-1 particiones y lo valida en la partición restante. Este proceso se repite k veces, y se promedian los resultados.\n",
    "\n",
    "**Ventajas**:\n",
    "\n",
    "- Proporciona una estimación más confiable del rendimiento del modelo.\n",
    "\n",
    "- Ayuda a detectar sobreajuste.\n",
    "\n",
    "**Desventajas**:\n",
    "\n",
    "- Computacionalmente más costoso que una sola división entrenamiento/prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd97ed-abbe-42c7-b46c-b25b955bf1bc",
   "metadata": {},
   "source": [
    "### Uso de CrossValidator y ParamGridBuilder en Spark MLlib\n",
    "Spark MLlib proporciona herramientas integradas para realizar Grid Search y Cross-Validation de manera eficiente en grandes conjuntos de datos distribuidos.\n",
    "\n",
    "#### **1. ParamGridBuilder**\n",
    "\n",
    "- Permite definir una \"rejilla\" de hiperparámetros para probar.\n",
    "\n",
    "- Por ejemplo, puedes especificar diferentes valores para la profundidad máxima de un árbol o el número de árboles en un Random Forest.\n",
    "\n",
    "**Ejemplo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f74d0-7d7a-47d5-adff-1bb6bb7cc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.tuning.ParamGridBuilder\n",
    "\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(rf.maxDepth, Array(5, 10, 15)) // Profundidad máxima del árbol\n",
    "  .addGrid(rf.numTrees, Array(10, 50, 100)) // Número de árboles\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85121c8d-2e43-47c7-bdd8-1920eaa7cd85",
   "metadata": {},
   "source": [
    "#### **2. CrossValidator**\n",
    "\n",
    "- Combina Grid Search con Cross-Validation.\n",
    "\n",
    "- Entrena y evalúa el modelo para cada combinación de hiperparámetros en la rejilla, utilizando validación cruzada.\n",
    "\n",
    "- Selecciona la combinación de hiperparámetros que produce el mejor rendimiento.\n",
    "\n",
    "**Ejemplo**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74861be0-84e7-44ee-9bf1-82410774962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.tuning.CrossValidator\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "\n",
    "val evaluator = new RegressionEvaluator()\n",
    "  .setLabelCol(\"quality\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline) // Pipeline con el modelo\n",
    "  .setEvaluator(evaluator) // Métrica de evaluación\n",
    "  .setEstimatorParamMaps(paramGrid) // Rejilla de hiperparámetros\n",
    "  .setNumFolds(5) // Número de folds en la validación cruzada\n",
    "  .setParallelism(2) // Número de hilos para ejecución en paralelo\n",
    "\n",
    "val cvModel = cv.fit(trainingData) // Entrenar el modelo con Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b4f17-46b5-4568-ae23-26eddbf89504",
   "metadata": {},
   "source": [
    "#### Flujo de Trabajo en Spark MLlib  \n",
    "\n",
    "**1. Definir el Pipeline**:\n",
    "\n",
    "- Incluye todas las transformaciones y el modelo.\n",
    "\n",
    "**2. Definir la rejilla de hiperparámetros**:\n",
    "\n",
    "- Usa **ParamGridBuilder** para especificar los valores de los hiperparámetros.\n",
    "\n",
    "**3. Configurar CrossValidator**:\n",
    "\n",
    "- Especifica el pipeline, la métrica de evaluación, la rejilla de hiperparámetros y el número de folds.\n",
    "\n",
    "**4. Entrenar el modelo**:\n",
    "\n",
    "- Usa **CrossValidator.fit()** para entrenar el modelo con validación cruzada.\n",
    "\n",
    "**5. Evaluar el modelo**:\n",
    "\n",
    "- Usa el modelo entrenado para hacer predicciones y evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75806b-74f5-456e-87e2-2d2be94899b3",
   "metadata": {},
   "source": [
    "### Grid Search y CrossValidator Juntos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8afbd-6851-466e-96d2-bebae98ae6a7",
   "metadata": {},
   "source": [
    "**1. ParamGridBuilder** define las combinaciones de hiperparámetros que se probarán.\n",
    "\n",
    "**2. CrossValidator** toma esa rejilla y:\n",
    "\n",
    "- Divide los datos en k folds (por ejemplo, 5 folds).\n",
    "\n",
    "- Para cada combinación de hiperparámetros:\n",
    "\n",
    "  - Entrena el modelo en k-1 folds.\n",
    "\n",
    "  - Evalúa el modelo en el fold restante.\n",
    "\n",
    "  - Repite este proceso k veces (una vez para cada fold).\n",
    "\n",
    "- Calcula el rendimiento promedio del modelo para cada combinación de hiperparámetros.\n",
    "\n",
    "**3. Finalmente, CrossValidator** selecciona la combinación de hiperparámetros que produce el mejor rendimiento promedio.\n",
    "\n",
    "**Ejemplo Completo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b742b-4091-4cfe-9322-cdbf2c368b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n",
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "// 1. Crear una sesión de Spark\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"Grid Search with CrossValidator\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()\n",
    "\n",
    "// 2. Cargar el dataset winequality-red\n",
    "val data = spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"path/to/winequality-red.csv\") // Reemplaza con la ruta correcta\n",
    "\n",
    "// 3. Preparar los datos: Crear un vector de características\n",
    "val featureColumns = Array(\n",
    "  \"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\",\n",
    "  \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\",\n",
    "  \"pH\", \"sulphates\", \"alcohol\"\n",
    ")\n",
    "\n",
    "val assembler = new VectorAssembler()\n",
    "  .setInputCols(featureColumns)\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val assembledData = assembler.transform(data)\n",
    "\n",
    "// 4. Dividir los datos en conjuntos de entrenamiento y prueba (80% - 20%)\n",
    "val Array(trainingData, testData) = assembledData.randomSplit(Array(0.8, 0.2), seed = 42)\n",
    "\n",
    "// 5. Definir el modelo (Random Forest Regressor)\n",
    "val rf = new RandomForestRegressor()\n",
    "  .setLabelCol(\"quality\")\n",
    "  .setFeaturesCol(\"features\")\n",
    "\n",
    "// 6. Definir la rejilla de hiperparámetros con ParamGridBuilder\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(rf.maxDepth, Array(5, 10, 15)) // Profundidad máxima del árbol\n",
    "  .addGrid(rf.numTrees, Array(10, 50, 100)) // Número de árboles\n",
    "  .build()\n",
    "\n",
    "// 7. Definir el evaluador (usaremos RMSE)\n",
    "val evaluator = new RegressionEvaluator()\n",
    "  .setLabelCol(\"quality\")\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "// 8. Crear el Pipeline\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(assembler, rf))\n",
    "\n",
    "// 9. Configurar CrossValidator\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline) // Pipeline con el modelo\n",
    "  .setEvaluator(evaluator) // Métrica de evaluación\n",
    "  .setEstimatorParamMaps(paramGrid) // Rejilla de hiperparámetros\n",
    "  .setNumFolds(5) // Número de folds en la validación cruzada\n",
    "  .setParallelism(2) // Número de hilos para ejecución en paralelo\n",
    "\n",
    "// 10. Entrenar el modelo con Cross-Validation\n",
    "val cvModel = cv.fit(trainingData)\n",
    "\n",
    "// 11. Obtener el mejor modelo\n",
    "val bestModel = cvModel.bestModel\n",
    "println(s\"Mejores hiperparámetros: ${bestModel.extractParamMap}\")\n",
    "\n",
    "// 12. Hacer predicciones sobre el conjunto de prueba\n",
    "val predictions = bestModel.transform(testData)\n",
    "predictions.select(\"quality\", \"prediction\").show(10)\n",
    "\n",
    "// 13. Evaluar el modelo\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(s\"Root Mean Squared Error (RMSE): $rmse\")\n",
    "\n",
    "// 14. Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06110df3-e087-4466-ba4e-457609b7ee2c",
   "metadata": {},
   "source": [
    "**1. ParamGridBuilder** define una rejilla de hiperparámetros para maxDepth y numTrees.\n",
    "\n",
    "**2. CrossValidator** prueba cada combinación de hiperparámetros utilizando validación cruzada.\n",
    "\n",
    "**3. Selecciona** la combinación de hiperparámetros que produce el menor RMSE (Error Cuadrático Medio).\n",
    "\n",
    "**4. Entrena** el modelo final con los mejores hiperparámetros y lo evalúa en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeca362-bc07-4691-8e70-9391b1fc5e3f",
   "metadata": {},
   "source": [
    "### ¿Cuándo es conveniente hacer un análisis completo de hiperparámetros?  \n",
    "\n",
    "**1. Cuando el rendimiento del modelo es crítico**:\n",
    "\n",
    "- Si estás trabajando en un problema donde el rendimiento del modelo es crucial (por ejemplo, en aplicaciones médicas, financieras o de seguridad), optimizar los hiperparámetros puede marcar una gran diferencia.\n",
    "\n",
    "**2. Cuando el modelo tiene muchos hiperparámetros**:\n",
    "\n",
    "- Algoritmos como Random Forest, Gradient Boosting (por ejemplo, XGBoost o LightGBM), o Redes Neuronales tienen varios hiperparámetros que pueden afectar significativamente el rendimiento. En estos casos, es casi obligatorio realizar una optimización.\n",
    "\n",
    "**3. Cuando tienes suficientes recursos computacionales**:\n",
    "\n",
    "- La optimización de hiperparámetros, especialmente con técnicas como Grid Search y Cross-Validation, puede ser costosa en términos de tiempo y recursos. Si tienes acceso a un clúster distribuido o a hardware potente, es más factible realizar un análisis completo.\n",
    "\n",
    "**4. Cuando el dataset es pequeño o mediano**:\n",
    "\n",
    "- En datasets pequeños o medianos, la optimización de hiperparámetros es más manejable computacionalmente. En datasets muy grandes, puede ser prohibitivo debido al tiempo y recursos requeridos.\n",
    "\n",
    "**5. Cuando buscas la mejor generalización**:\n",
    "\n",
    "- Si tu objetivo es que el modelo generalice bien a datos no vistos, la optimización de hiperparámetros con validación cruzada es una excelente manera de asegurarte de que el modelo no esté sobreajustado o subajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af15266-f042-4bab-8880-544dbd223a55",
   "metadata": {},
   "source": [
    "### ¿Cuándo podrías omitir el análisis completo de hiperparámetros?  \n",
    "\n",
    "**1. Cuando el tiempo o los recursos son limitados**:\n",
    "\n",
    "- Si estás en una fase exploratoria o prototipando un modelo, podrías usar valores por defecto o ajustar manualmente algunos hiperparámetros clave en lugar de realizar una búsqueda exhaustiva.\n",
    "\n",
    "**2. Cuando el modelo es simple**:\n",
    "\n",
    "- Para algoritmos simples como Regresión Lineal o Árboles de Decisión básicos, los hiperparámetros tienen menos impacto en el rendimiento, por lo que podrías omitir una búsqueda exhaustiva.\n",
    "\n",
    "**3. Cuando el dataset es muy grande**:\n",
    "\n",
    "- En datasets extremadamente grandes, el costo computacional de la optimización de hiperparámetros puede ser demasiado alto. En estos casos, podrías usar valores por defecto o ajustar manualmente algunos hiperparámetros.\n",
    "\n",
    "**4. Cuando ya tienes un conocimiento previo**:\n",
    "\n",
    "- Si ya sabes qué valores de hiperparámetros funcionan bien para tu problema (por ejemplo, por experiencia previa o por literatura), podrías usarlos directamente sin realizar una búsqueda exhaustiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ba6ef-2c69-4258-8ff0-4e6900271595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
